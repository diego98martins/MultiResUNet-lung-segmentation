{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SKD7jSvIn1T9"
   },
   "source": [
    "# Importing Modules\n",
    "\n",
    "The necessary modules are : os, opencv, numpy, tqdm, matplotlib, keras and sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nNtz_YYVnzcZ",
    "outputId": "21000b0d-93c5-4dcf-96f3-4bedc5d90a3c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables.segmaps import SegmentationMapsOnImage\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, BatchNormalization, Activation, add\n",
    "from tensorflow.keras.models import Model, model_from_json\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import ELU, LeakyReLU\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import backend as K \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fb1Dw_RroBkh"
   },
   "source": [
    "# Downloading Data\n",
    "\n",
    "Here, we download the image data and the corresponding ground truth segmentation masks.\n",
    "\n",
    "In the paper we had not tested on the ISIC-17 Dataset, which will be used here for the demo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xLkeS7Lxo_Po"
   },
   "source": [
    "# Constructing Training and Test Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gHo6ymwFpJzY"
   },
   "source": [
    "## Loading the Images\n",
    "\n",
    "We first load all the images and the corresponding segmentation masks. \n",
    "\n",
    "They are stored in two lists X, Y and respectively\n",
    "\n",
    "Moreover, the images are resized to 256x192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "YbeQ1aytHTm3",
    "outputId": "d43c1e52-d889-4a4f-96aa-5ef4d20b649f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 17/704 [00:00<00:04, 166.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704\n",
      "704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 704/704 [00:03<00:00, 181.89it/s]\n"
     ]
    }
   ],
   "source": [
    "img_files = next(os.walk('data/cxr'))[2]\n",
    "msk_files = next(os.walk('data/masks'))[2]\n",
    "\n",
    "img_files.sort()\n",
    "msk_files.sort()\n",
    "\n",
    "print(len(img_files))\n",
    "print(len(msk_files))\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for img_fl in tqdm(img_files):    \n",
    "    if(img_fl.split('.')[-1]=='png'):\n",
    "        \n",
    "        img = cv2.imread('data/cxr/{}'.format(img_fl), cv2.IMREAD_COLOR)\n",
    "        resized_img = cv2.resize(img,(64, 64), interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "        X.append(resized_img)\n",
    "\n",
    "        msk = cv2.imread('data/masks/{}'.format(img_fl), cv2.IMREAD_GRAYSCALE)\n",
    "        resized_msk = cv2.resize(msk,(64, 64), interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "        Y.append(resized_msk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cxr = []\n",
    "masks = []\n",
    "\n",
    "for i in range(len(X)):\n",
    "    # Load an example image (uint8, 128x128x3).\n",
    "    image = np.array(X[i], dtype=np.uint8)\n",
    "\n",
    "    # Define an example segmentation map (int32, 128x128).\n",
    "    # Here, we arbitrarily place some squares on the image.\n",
    "    # Class 0 is our intended background class.\n",
    "\n",
    "    segmap = np.array(Y[i])\n",
    "    segmap = segmap / 255\n",
    "    segmap = np.around(segmap, decimals=0)\n",
    "    segmap = np.array(segmap, dtype=np.int32)\n",
    "\n",
    "    segmap = SegmentationMapsOnImage(segmap, shape=image.shape)\n",
    "\n",
    "    # Define our augmentation pipeline.\n",
    "    seq = iaa.Sequential([\n",
    "#         iaa.Dropout([0.0, 0.004]),      # drop 5% or 20% of all pixels\n",
    "#         iaa.Sharpen((0.0, 1.0)),       # sharpen the image\n",
    "        iaa.Affine(\n",
    "            scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)},\n",
    "            translate_percent={\"x\": (-0.05, 0.05), \"y\": (-0.05, 0.05)},\n",
    "            rotate=(-10, 10),\n",
    "            shear=(-8, 8)\n",
    "        ),\n",
    "#         iaa.ElasticTransformation(alpha=0.1, sigma=0.03),  # apply water effect (affects segmaps)\n",
    "#         iaa.Fliplr(0.5),\n",
    "#         iaa.LinearContrast((0.75, 1.5)),\n",
    "#         iaa.Crop(percent=(0, 0.05)), # random crops\n",
    "\n",
    "        iaa.Sometimes(\n",
    "            0.5,\n",
    "            iaa.GaussianBlur(sigma=(0, 0.5))\n",
    "        ),\n",
    "    ], random_order=True)\n",
    "\n",
    "    # Augment images and segmaps.\n",
    "    images_aug = []\n",
    "    segmaps_aug = []\n",
    "    for _ in range(1): #how many augumentation per image?\n",
    "        images_aug_i, segmaps_aug_i = seq(image=image, segmentation_maps=segmap)\n",
    "        images_aug.append(images_aug_i)\n",
    "        segmaps_aug.append(segmaps_aug_i)\n",
    "\n",
    "\n",
    "    for image_aug, segmap_aug in zip(images_aug, segmaps_aug):\n",
    "        cxr.append(image_aug)                                     # column 3\n",
    "        masks.append(segmap_aug.draw(size=image_aug.shape[:2])[0])  # column 5\n",
    "        \n",
    "cxr_n = np.array(cxr)\n",
    "masks_n = np.array(masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jYgEz9HQpgsR"
   },
   "source": [
    "## Train-Test Split\n",
    "\n",
    "The X, Y lists are converted to numpy arrays for convenience. \n",
    "Furthermore, the images are divided by 255 to bring down the pixel values to [0...1] range. On the other hand the segmentations masks are converted to binary (0 or 1) values.\n",
    "\n",
    "Using Sklearn *train_test_split* we split the data randomly into 80% training and 20% testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "CxFIZv3715Dt",
    "outputId": "5a93db60-ed50-4122-8aa0-b26e42a601ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704\n",
      "704\n",
      "(696, 64, 64)\n",
      "(696, 64, 64, 1)\n",
      "(8, 64, 64)\n",
      "(8, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "for i in range(len(cxr_n)):\n",
    "    msk = cv2.cvtColor(masks_n[i], cv2.COLOR_BGR2GRAY)\n",
    "    msk = cv2.medianBlur(msk, 5)\n",
    "    \n",
    "    cxr = cv2.cvtColor(cxr_n[i], cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    X.append(cxr)\n",
    "    Y.append(msk)\n",
    "\n",
    "\n",
    "print(len(X))\n",
    "print(len(Y))\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.01, random_state=3)\n",
    "\n",
    "Y_train = Y_train.reshape((Y_train.shape[0],Y_train.shape[1],Y_train.shape[2],1))\n",
    "Y_test = Y_test.reshape((Y_test.shape[0],Y_test.shape[1],Y_test.shape[2],1))\n",
    "\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "#already did in data augumentation\n",
    "# Y_train = Y_train / 255\n",
    "# Y_test = Y_test / 255\n",
    "\n",
    "Y_train = np.round(Y_train,0)\n",
    "Y_test = np.round(Y_test,0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C-Ajp2QVrMti"
   },
   "source": [
    "# MultiResUNet Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "21cbmiojrYrU"
   },
   "source": [
    "## Model Definition\n",
    "\n",
    "The MultiResUNet model as described in the [paper](https://arxiv.org/abs/1902.04049) can be found  [here](https://github.com/nibtehaz/MultiResUNet/blob/master/MultiResUNet.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2nX7I1Wf_zEy"
   },
   "outputs": [],
   "source": [
    "def conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(1, 1), activation='relu', name=None):\n",
    "    '''\n",
    "    2D Convolutional layers\n",
    "    \n",
    "    Arguments:\n",
    "        x {keras layer} -- input layer \n",
    "        filters {int} -- number of filters\n",
    "        num_row {int} -- number of rows in filters\n",
    "        num_col {int} -- number of columns in filters\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        padding {str} -- mode of padding (default: {'same'})\n",
    "        strides {tuple} -- stride of convolution operation (default: {(1, 1)})\n",
    "        activation {str} -- activation function (default: {'relu'})\n",
    "        name {str} -- name of the layer (default: {None})\n",
    "    \n",
    "    Returns:\n",
    "        [keras layer] -- [output layer]\n",
    "    '''\n",
    "\n",
    "    x = Conv2D(filters, (num_row, num_col), strides=strides, padding=padding, use_bias=False)(x)\n",
    "    x = BatchNormalization(axis=3, scale=False)(x)\n",
    "\n",
    "    if(activation == None):\n",
    "        return x\n",
    "\n",
    "    x = Activation(activation, name=name)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def trans_conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(2, 2), name=None):\n",
    "    '''\n",
    "    2D Transposed Convolutional layers\n",
    "    \n",
    "    Arguments:\n",
    "        x {keras layer} -- input layer \n",
    "        filters {int} -- number of filters\n",
    "        num_row {int} -- number of rows in filters\n",
    "        num_col {int} -- number of columns in filters\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        padding {str} -- mode of padding (default: {'same'})\n",
    "        strides {tuple} -- stride of convolution operation (default: {(2, 2)})\n",
    "        name {str} -- name of the layer (default: {None})\n",
    "    \n",
    "    Returns:\n",
    "        [keras layer] -- [output layer]\n",
    "    '''\n",
    "\n",
    "    x = Conv2DTranspose(filters, (num_row, num_col), strides=strides, padding=padding)(x)\n",
    "    x = BatchNormalization(axis=3, scale=False)(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def MultiResBlock(U, inp, alpha = 1.67):\n",
    "    '''\n",
    "    MultiRes Block\n",
    "    \n",
    "    Arguments:\n",
    "        U {int} -- Number of filters in a corrsponding UNet stage\n",
    "        inp {keras layer} -- input layer \n",
    "    \n",
    "    Returns:\n",
    "        [keras layer] -- [output layer]\n",
    "    '''\n",
    "\n",
    "    W = alpha * U\n",
    "\n",
    "    shortcut = inp\n",
    "\n",
    "    shortcut = conv2d_bn(shortcut, int(W*0.167) + int(W*0.333) +\n",
    "                         int(W*0.5), 1, 1, activation=None, padding='same')\n",
    "\n",
    "    conv3x3 = conv2d_bn(inp, int(W*0.167), 3, 3,\n",
    "                        activation='relu', padding='same')\n",
    "\n",
    "    conv5x5 = conv2d_bn(conv3x3, int(W*0.333), 3, 3,\n",
    "                        activation='relu', padding='same')\n",
    "\n",
    "    conv7x7 = conv2d_bn(conv5x5, int(W*0.5), 3, 3,\n",
    "                        activation='relu', padding='same')\n",
    "\n",
    "    out = concatenate([conv3x3, conv5x5, conv7x7], axis=3)\n",
    "    out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    out = add([shortcut, out])\n",
    "    out = Activation('relu')(out)\n",
    "    out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def ResPath(filters, length, inp):\n",
    "    '''\n",
    "    ResPath\n",
    "    \n",
    "    Arguments:\n",
    "        filters {int} -- [description]\n",
    "        length {int} -- length of ResPath\n",
    "        inp {keras layer} -- input layer \n",
    "    \n",
    "    Returns:\n",
    "        [keras layer] -- [output layer]\n",
    "    '''\n",
    "\n",
    "\n",
    "    shortcut = inp\n",
    "    shortcut = conv2d_bn(shortcut, filters, 1, 1,\n",
    "                         activation=None, padding='same')\n",
    "\n",
    "    out = conv2d_bn(inp, filters, 3, 3, activation='relu', padding='same')\n",
    "\n",
    "    out = add([shortcut, out])\n",
    "    out = Activation('relu')(out)\n",
    "    out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    for i in range(length-1):\n",
    "\n",
    "        shortcut = out\n",
    "        shortcut = conv2d_bn(shortcut, filters, 1, 1,\n",
    "                             activation=None, padding='same')\n",
    "\n",
    "        out = conv2d_bn(out, filters, 3, 3, activation='relu', padding='same')\n",
    "\n",
    "        out = add([shortcut, out])\n",
    "        out = Activation('relu')(out)\n",
    "        out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def MultiResUnet(height, width, n_channels):\n",
    "    '''\n",
    "    MultiResUNet\n",
    "    \n",
    "    Arguments:\n",
    "        height {int} -- height of image \n",
    "        width {int} -- width of image \n",
    "        n_channels {int} -- number of channels in image\n",
    "    \n",
    "    Returns:\n",
    "        [keras model] -- MultiResUNet model\n",
    "    '''\n",
    "\n",
    "\n",
    "    inputs = Input((height, width, n_channels))\n",
    "\n",
    "    mresblock1 = MultiResBlock(32, inputs)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(mresblock1)\n",
    "    mresblock1 = ResPath(32, 4, mresblock1)\n",
    "\n",
    "    mresblock2 = MultiResBlock(32*2, pool1)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(mresblock2)\n",
    "    mresblock2 = ResPath(32*2, 3, mresblock2)\n",
    "\n",
    "    mresblock3 = MultiResBlock(32*4, pool2)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(mresblock3)\n",
    "    mresblock3 = ResPath(32*4, 2, mresblock3)\n",
    "\n",
    "    mresblock4 = MultiResBlock(32*8, pool3)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(mresblock4)\n",
    "    mresblock4 = ResPath(32*8, 1, mresblock4)\n",
    "\n",
    "    mresblock5 = MultiResBlock(32*16, pool4)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(\n",
    "        32*8, (2, 2), strides=(2, 2), padding='same')(mresblock5), mresblock4], axis=3)\n",
    "    mresblock6 = MultiResBlock(32*8, up6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(\n",
    "        32*4, (2, 2), strides=(2, 2), padding='same')(mresblock6), mresblock3], axis=3)\n",
    "    mresblock7 = MultiResBlock(32*4, up7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(\n",
    "        32*2, (2, 2), strides=(2, 2), padding='same')(mresblock7), mresblock2], axis=3)\n",
    "    mresblock8 = MultiResBlock(32*2, up8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(\n",
    "        2, 2), padding='same')(mresblock8), mresblock1], axis=3)\n",
    "    mresblock9 = MultiResBlock(32, up9)\n",
    "\n",
    "    conv10 = conv2d_bn(mresblock9, 1, 1, 1, activation='sigmoid')\n",
    "    \n",
    "    model = Model(inputs=[inputs], outputs=[conv10])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2frZlpmFsv1f"
   },
   "source": [
    "## Auxiliary Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "degBGBWYsyNG"
   },
   "source": [
    "### Custom Metrics\n",
    "\n",
    "Since Keras does not have build-in support for computing Dice Coefficient or Jaccard Index (at the time of writing), the following functions are declared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xq8qfLqDA6q2"
   },
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    smooth = 0.0\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def jacard(y_true, y_pred):\n",
    "\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum ( y_true_f * y_pred_f)\n",
    "    union = K.sum ( y_true_f + y_pred_f - y_true_f * y_pred_f)\n",
    "\n",
    "    return intersection/union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VtvyeBXy8Mk3"
   },
   "source": [
    "### Saving Model \n",
    "\n",
    "Function to save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GCfX9MUYALar"
   },
   "outputs": [],
   "source": [
    "def saveModel(model):\n",
    "\n",
    "    model_json = model.to_json()\n",
    "\n",
    "    try:\n",
    "        os.makedirs('models')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    fp = open('models/modelP.json','w')\n",
    "    fp.write(model_json)\n",
    "    model.save_weights('models/modelW.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AH3znjx-8vDq"
   },
   "source": [
    "### Evaluate the Model\n",
    "\n",
    "We evaluate the model on test data (X_test, Y_test). \n",
    "\n",
    "We compute the values of Jaccard Index and Dice Coeficient, and save the predicted segmentation of first 10 images. The best model is also saved\n",
    "\n",
    "(This could have been done using keras call-backs as well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tkit_YYvBQ7V"
   },
   "outputs": [],
   "source": [
    "def evaluateModel(model, X_test, Y_test, batchSize):\n",
    "    \n",
    "    try:\n",
    "        os.makedirs('results')\n",
    "    except:\n",
    "        pass \n",
    "    \n",
    "\n",
    "    yp = model.predict(x=X_test, batch_size=batchSize, verbose=1)\n",
    "\n",
    "    yp = np.round(yp,0)\n",
    "\n",
    "    for i in range(X_test.shape[0]):\n",
    "\n",
    "        plt.figure(figsize=(20,10))\n",
    "        plt.subplot(1,3,1)\n",
    "        plt.imshow(X_test[i])\n",
    "        plt.title('Input')\n",
    "        plt.subplot(1,3,2)\n",
    "        plt.imshow(Y_test[i].reshape(Y_test[i].shape[0],Y_test[i].shape[1]))\n",
    "        plt.title('Ground Truth')\n",
    "        plt.subplot(1,3,3)\n",
    "        plt.imshow(yp[i].reshape(yp[i].shape[0],yp[i].shape[1]))\n",
    "        plt.title('Prediction')\n",
    "\n",
    "        intersection = yp[i].ravel() * Y_test[i].ravel()\n",
    "        union = yp[i].ravel() + Y_test[i].ravel() - intersection\n",
    "\n",
    "        jacard = (np.sum(intersection)/np.sum(union))  \n",
    "        plt.suptitle('Jacard Index'+ str(np.sum(intersection)) +'/'+ str(np.sum(union)) +'='+str(jacard))\n",
    "\n",
    "        plt.savefig('results/'+str(i)+'.png',format='png')\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "    jacard = 0\n",
    "    dice = 0\n",
    "    \n",
    "    \n",
    "    for i in range(len(Y_test)):\n",
    "        yp_2 = yp[i].ravel()\n",
    "        y2 = Y_test[i].ravel()\n",
    "        \n",
    "        intersection = yp_2 * y2\n",
    "        union = yp_2 + y2 - intersection\n",
    "\n",
    "        jacard += (np.sum(intersection)/np.sum(union))  \n",
    "\n",
    "        dice += (2. * np.sum(intersection) ) / (np.sum(yp_2) + np.sum(y2))\n",
    "\n",
    "    \n",
    "    jacard /= len(Y_test)\n",
    "    dice /= len(Y_test)\n",
    "    \n",
    "\n",
    "\n",
    "    print('Jacard Index : '+str(jacard))\n",
    "    print('Dice Coefficient : '+str(dice))\n",
    "    \n",
    "\n",
    "    fp = open('models/log.txt','a')\n",
    "    fp.write(str(jacard)+'\\n')\n",
    "    fp.close()\n",
    "\n",
    "    fp = open('models/best.txt','r')\n",
    "    best = fp.read()\n",
    "    fp.close()\n",
    "\n",
    "    if(jacard>float(best)):\n",
    "        print('***********************************************')\n",
    "        print('Jacard Index improved from '+str(best)+' to '+str(jacard))\n",
    "        print('***********************************************')\n",
    "        fp = open('models/best.txt','w')\n",
    "        fp.write(str(jacard))\n",
    "        fp.close()\n",
    "\n",
    "        saveModel(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "80IwnKtM9NHY"
   },
   "source": [
    "### Training the Model\n",
    "\n",
    "The model is trained and evaluated after each epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wlOOh0-nA05L"
   },
   "outputs": [],
   "source": [
    "def trainStep(model, X_train, Y_train, X_test, Y_test, epochs, batchSize):\n",
    "\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch : {}'.format(epoch+1))\n",
    "        model.fit(x=X_train, y=Y_train, batch_size=batchSize, epochs=1, verbose=1)     \n",
    "\n",
    "        evaluateModel(model,X_test, Y_test,batchSize)\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4wJ5V9AJ9Ygu"
   },
   "source": [
    "## Define Model, Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1105
    },
    "colab_type": "code",
    "id": "GJqeuZPhDZSK",
    "outputId": "b1344374-f69e-4805-a22d-b8152f07b754",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1\n",
      "239/696 [=========>....................] - ETA: 1:33 - loss: -25.0645 - dice_coef: 1.6044 - jacard: 4.2467 - accuracy: 0.6936"
     ]
    }
   ],
   "source": [
    "model = MultiResUnet(height=64, width=64, n_channels=1)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef, jacard, 'accuracy'])\n",
    "\n",
    "saveModel(model)\n",
    "\n",
    "fp = open('models/log.txt','w')\n",
    "fp.close()\n",
    "fp = open('models/best.txt','w')\n",
    "fp.write('-1.0')\n",
    "fp.close()\n",
    "    \n",
    "trainStep(model, X_train, Y_train, X_test, Y_test, epochs=10, batchSize=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ISIC.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
