{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SKD7jSvIn1T9"
   },
   "source": [
    "# Importing Modules\n",
    "\n",
    "The necessary modules are : os, opencv, numpy, tqdm, matplotlib, imgaug, tensorflow and sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nNtz_YYVnzcZ",
    "outputId": "21000b0d-93c5-4dcf-96f3-4bedc5d90a3c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables.segmaps import SegmentationMapsOnImage\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, BatchNormalization, Activation, add\n",
    "from tensorflow.keras.models import Model, model_from_json\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import ELU, LeakyReLU\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import backend as K \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xLkeS7Lxo_Po"
   },
   "source": [
    "# Constructing Training and Test Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gHo6ymwFpJzY"
   },
   "source": [
    "## Loading the Images\n",
    "\n",
    "We first load all the images and the corresponding segmentation masks. \n",
    "\n",
    "They are stored in two lists X, Y and respectively\n",
    "\n",
    "Moreover, the images are resized to 64x64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "YbeQ1aytHTm3",
    "outputId": "d43c1e52-d889-4a4f-96aa-5ef4d20b649f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 16/704 [00:00<00:04, 158.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704\n",
      "704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 704/704 [00:03<00:00, 209.01it/s]\n"
     ]
    }
   ],
   "source": [
    "img_files = next(os.walk('data/cxr'))[2]\n",
    "msk_files = next(os.walk('data/masks'))[2]\n",
    "\n",
    "img_files.sort()\n",
    "msk_files.sort()\n",
    "\n",
    "print(len(img_files))\n",
    "print(len(msk_files))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for img_fl in tqdm(img_files):    \n",
    "    if(img_fl.split('.')[-1]=='png'):\n",
    "                \n",
    "        \n",
    "        img = cv2.imread('data/cxr/{}'.format(img_fl), cv2.IMREAD_GRAYSCALE) #cv2.IMREAD_COLOR for augumentation\n",
    "        resized_img = cv2.resize(img,(64, 64), interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "        X.append(resized_img)\n",
    "\n",
    "        msk = cv2.imread('data/masks/{}'.format(img_fl), cv2.IMREAD_GRAYSCALE)\n",
    "        resized_msk = cv2.resize(msk,(64, 64), interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "        Y.append(resized_msk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation\n",
    "\n",
    "We generate more data for training using the original dataset.\n",
    "\n",
    "Operations:\n",
    "\n",
    "* dropout pixels\n",
    "* change scale\n",
    "* rotate\n",
    "* horizontal flip\n",
    "* crop\n",
    "* contrast\n",
    "* and others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "masks = []\n",
    "\n",
    "for i in range(len(X)):\n",
    "    # Load an example image (uint8, 64x64).\n",
    "    image = np.array(X[i], dtype=np.uint8)\n",
    "\n",
    "    # Define an example segmentation map (int32, 64x64).\n",
    "    segmap = np.array(Y[i])\n",
    "    segmap = segmap / 255\n",
    "    segmap = np.around(segmap, decimals=0)\n",
    "    segmap = np.array(segmap, dtype=np.int32)\n",
    "\n",
    "    segmap = SegmentationMapsOnImage(segmap, shape=image.shape)\n",
    "\n",
    "    # Define our augmentation pipeline.\n",
    "    seq = iaa.Sequential([\n",
    "        iaa.Dropout([0.0, 0.004]),      # drop 0% to 0.4% of all pixels\n",
    "        iaa.Sharpen((0.0, 1.0)),       # sharpen the image\n",
    "        iaa.Affine(\n",
    "            scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)},\n",
    "            translate_percent={\"x\": (-0.05, 0.05), \"y\": (-0.05, 0.05)},\n",
    "            rotate=(-10, 10),\n",
    "            shear=(-8, 8)\n",
    "        ),\n",
    "        iaa.ElasticTransformation(alpha=0.1, sigma=0.03),\n",
    "        iaa.Fliplr(0.5),\n",
    "        iaa.LinearContrast((0.75, 1.5)),\n",
    "        iaa.Crop(percent=(0, 0.05)),\n",
    "\n",
    "        iaa.Sometimes(\n",
    "            0.5,\n",
    "            iaa.GaussianBlur(sigma=(0, 0.5))\n",
    "        ),\n",
    "    ], random_order=True)\n",
    "\n",
    "    # Augment images and segmaps.\n",
    "    images_aug = []\n",
    "    segmaps_aug = []\n",
    "    for _ in range(1): #how many augumentation per image? e.g. range(1) = 1 new image\n",
    "        images_aug_i, segmaps_aug_i = seq(image=image, segmentation_maps=segmap)\n",
    "        images_aug.append(images_aug_i)\n",
    "        segmaps_aug.append(segmaps_aug_i)\n",
    "\n",
    "\n",
    "    for image_aug, segmap_aug in zip(images_aug, segmaps_aug):\n",
    "        imgs.append(image_aug)  \n",
    "        \n",
    "        mask = cv2.cvtColor(segmap_aug.draw(size=image_aug.shape[:2])[0], cv2.COLOR_BGR2GRAY)\n",
    "        mask = cv2.medianBlur(mask, 5)\n",
    "        masks.append(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jYgEz9HQpgsR"
   },
   "source": [
    "## Train-Test Split\n",
    "\n",
    "The X, Y lists are converted to numpy arrays for convenience. \n",
    "Furthermore, the images are divided by 255 to bring down the pixel values to [0...1] range. On the other hand the segmentations masks are converted to binary (0 or 1) values.\n",
    "\n",
    "Using Sklearn *train_test_split* we split the data randomly into 80% training and 20% testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "CxFIZv3715Dt",
    "outputId": "5a93db60-ed50-4122-8aa0-b26e42a601ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704\n",
      "704\n",
      "(633, 64, 64)\n",
      "(633, 64, 64, 1)\n",
      "(71, 64, 64)\n",
      "(71, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "print(len(imgs))\n",
    "print(len(masks))\n",
    "\n",
    "X = np.array(imgs)\n",
    "Y = np.array(masks)\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=3)\n",
    "\n",
    "Y_train = Y_train.reshape((Y_train.shape[0],Y_train.shape[1],Y_train.shape[2],1))\n",
    "Y_test = Y_test.reshape((Y_test.shape[0],Y_test.shape[1],Y_test.shape[2],1))\n",
    "\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "Y_train = np.where(Y_train == 0, 0, 1)\n",
    "Y_test = np.where(Y_test == 0, 0, 1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C-Ajp2QVrMti"
   },
   "source": [
    "# MultiResUNet Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "21cbmiojrYrU"
   },
   "source": [
    "## Model Definition\n",
    "\n",
    "The MultiResUNet model as described in the [paper](https://arxiv.org/abs/1902.04049) can be found  [here](https://github.com/nibtehaz/MultiResUNet/blob/master/MultiResUNet.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2nX7I1Wf_zEy"
   },
   "outputs": [],
   "source": [
    "def conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(1, 1), activation='relu', name=None):\n",
    "    '''\n",
    "    2D Convolutional layers\n",
    "    \n",
    "    Arguments:\n",
    "        x {keras layer} -- input layer \n",
    "        filters {int} -- number of filters\n",
    "        num_row {int} -- number of rows in filters\n",
    "        num_col {int} -- number of columns in filters\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        padding {str} -- mode of padding (default: {'same'})\n",
    "        strides {tuple} -- stride of convolution operation (default: {(1, 1)})\n",
    "        activation {str} -- activation function (default: {'relu'})\n",
    "        name {str} -- name of the layer (default: {None})\n",
    "    \n",
    "    Returns:\n",
    "        [keras layer] -- [output layer]\n",
    "    '''\n",
    "\n",
    "    x = Conv2D(filters, (num_row, num_col), strides=strides, padding=padding, use_bias=False)(x)\n",
    "    x = BatchNormalization(axis=3, scale=False)(x)\n",
    "\n",
    "    if(activation == None):\n",
    "        return x\n",
    "\n",
    "    x = Activation(activation, name=name)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def trans_conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(2, 2), name=None):\n",
    "    '''\n",
    "    2D Transposed Convolutional layers\n",
    "    \n",
    "    Arguments:\n",
    "        x {keras layer} -- input layer \n",
    "        filters {int} -- number of filters\n",
    "        num_row {int} -- number of rows in filters\n",
    "        num_col {int} -- number of columns in filters\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        padding {str} -- mode of padding (default: {'same'})\n",
    "        strides {tuple} -- stride of convolution operation (default: {(2, 2)})\n",
    "        name {str} -- name of the layer (default: {None})\n",
    "    \n",
    "    Returns:\n",
    "        [keras layer] -- [output layer]\n",
    "    '''\n",
    "\n",
    "    x = Conv2DTranspose(filters, (num_row, num_col), strides=strides, padding=padding)(x)\n",
    "    x = BatchNormalization(axis=3, scale=False)(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def MultiResBlock(U, inp, alpha = 1.67):\n",
    "    '''\n",
    "    MultiRes Block\n",
    "    \n",
    "    Arguments:\n",
    "        U {int} -- Number of filters in a corrsponding UNet stage\n",
    "        inp {keras layer} -- input layer \n",
    "    \n",
    "    Returns:\n",
    "        [keras layer] -- [output layer]\n",
    "    '''\n",
    "\n",
    "    W = alpha * U\n",
    "\n",
    "    shortcut = inp\n",
    "\n",
    "    shortcut = conv2d_bn(shortcut, int(W*0.167) + int(W*0.333) +\n",
    "                         int(W*0.5), 1, 1, activation=None, padding='same')\n",
    "\n",
    "    conv3x3 = conv2d_bn(inp, int(W*0.167), 3, 3,\n",
    "                        activation='relu', padding='same')\n",
    "\n",
    "    conv5x5 = conv2d_bn(conv3x3, int(W*0.333), 3, 3,\n",
    "                        activation='relu', padding='same')\n",
    "\n",
    "    conv7x7 = conv2d_bn(conv5x5, int(W*0.5), 3, 3,\n",
    "                        activation='relu', padding='same')\n",
    "\n",
    "    out = concatenate([conv3x3, conv5x5, conv7x7], axis=3)\n",
    "    out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    out = add([shortcut, out])\n",
    "    out = Activation('relu')(out)\n",
    "    out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def ResPath(filters, length, inp):\n",
    "    '''\n",
    "    ResPath\n",
    "    \n",
    "    Arguments:\n",
    "        filters {int} -- [description]\n",
    "        length {int} -- length of ResPath\n",
    "        inp {keras layer} -- input layer \n",
    "    \n",
    "    Returns:\n",
    "        [keras layer] -- [output layer]\n",
    "    '''\n",
    "\n",
    "\n",
    "    shortcut = inp\n",
    "    shortcut = conv2d_bn(shortcut, filters, 1, 1,\n",
    "                         activation=None, padding='same')\n",
    "\n",
    "    out = conv2d_bn(inp, filters, 3, 3, activation='relu', padding='same')\n",
    "\n",
    "    out = add([shortcut, out])\n",
    "    out = Activation('relu')(out)\n",
    "    out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    for i in range(length-1):\n",
    "\n",
    "        shortcut = out\n",
    "        shortcut = conv2d_bn(shortcut, filters, 1, 1,\n",
    "                             activation=None, padding='same')\n",
    "\n",
    "        out = conv2d_bn(out, filters, 3, 3, activation='relu', padding='same')\n",
    "\n",
    "        out = add([shortcut, out])\n",
    "        out = Activation('relu')(out)\n",
    "        out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def MultiResUnet(height, width, n_channels):\n",
    "    '''\n",
    "    MultiResUNet\n",
    "    \n",
    "    Arguments:\n",
    "        height {int} -- height of image \n",
    "        width {int} -- width of image \n",
    "        n_channels {int} -- number of channels in image\n",
    "    \n",
    "    Returns:\n",
    "        [keras model] -- MultiResUNet model\n",
    "    '''\n",
    "\n",
    "\n",
    "    inputs = Input((height, width, n_channels))\n",
    "\n",
    "    mresblock1 = MultiResBlock(32, inputs)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(mresblock1)\n",
    "    mresblock1 = ResPath(32, 4, mresblock1)\n",
    "\n",
    "    mresblock2 = MultiResBlock(32*2, pool1)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(mresblock2)\n",
    "    mresblock2 = ResPath(32*2, 3, mresblock2)\n",
    "\n",
    "    mresblock3 = MultiResBlock(32*4, pool2)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(mresblock3)\n",
    "    mresblock3 = ResPath(32*4, 2, mresblock3)\n",
    "\n",
    "    mresblock4 = MultiResBlock(32*8, pool3)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(mresblock4)\n",
    "    mresblock4 = ResPath(32*8, 1, mresblock4)\n",
    "\n",
    "    mresblock5 = MultiResBlock(32*16, pool4)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(\n",
    "        32*8, (2, 2), strides=(2, 2), padding='same')(mresblock5), mresblock4], axis=3)\n",
    "    mresblock6 = MultiResBlock(32*8, up6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(\n",
    "        32*4, (2, 2), strides=(2, 2), padding='same')(mresblock6), mresblock3], axis=3)\n",
    "    mresblock7 = MultiResBlock(32*4, up7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(\n",
    "        32*2, (2, 2), strides=(2, 2), padding='same')(mresblock7), mresblock2], axis=3)\n",
    "    mresblock8 = MultiResBlock(32*2, up8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(\n",
    "        2, 2), padding='same')(mresblock8), mresblock1], axis=3)\n",
    "    mresblock9 = MultiResBlock(32, up9)\n",
    "\n",
    "    conv10 = conv2d_bn(mresblock9, 1, 1, 1, activation='sigmoid')\n",
    "    \n",
    "    model = Model(inputs=[inputs], outputs=[conv10])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2frZlpmFsv1f"
   },
   "source": [
    "## Auxiliary Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "degBGBWYsyNG"
   },
   "source": [
    "### Custom Metrics\n",
    "\n",
    "Since Keras does not have build-in support for computing Dice Coefficient or Jaccard Index (at the time of writing), the following functions are declared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xq8qfLqDA6q2"
   },
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    smooth = 0.0\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def jacard(y_true, y_pred):\n",
    "\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum ( y_true_f * y_pred_f)\n",
    "    union = K.sum ( y_true_f + y_pred_f - y_true_f * y_pred_f)\n",
    "\n",
    "    return intersection/union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VtvyeBXy8Mk3"
   },
   "source": [
    "### Saving Model \n",
    "\n",
    "Function to save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GCfX9MUYALar"
   },
   "outputs": [],
   "source": [
    "def saveModel(model):\n",
    "\n",
    "    model_json = model.to_json()\n",
    "\n",
    "    try:\n",
    "        os.makedirs('models')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    fp = open('models/modelP.json','w')\n",
    "    fp.write(model_json)\n",
    "    model.save_weights('models/modelW.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AH3znjx-8vDq"
   },
   "source": [
    "### Evaluate the Model\n",
    "\n",
    "We evaluate the model on test data (X_test, Y_test). \n",
    "\n",
    "We compute the values of Jaccard Index and Dice Coeficient, and save the predicted segmentation of first 10 images. The best model is also saved\n",
    "\n",
    "(This could have been done using keras call-backs as well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tkit_YYvBQ7V"
   },
   "outputs": [],
   "source": [
    "def evaluateModel(model, X_test, Y_test, batchSize):\n",
    "    \n",
    "    try:\n",
    "        os.makedirs('results')\n",
    "    except:\n",
    "        pass \n",
    "    \n",
    "\n",
    "    yp = model.predict(x=X_test, batch_size=batchSize, verbose=1)\n",
    "\n",
    "    yp = np.round(yp,0)\n",
    "\n",
    "    for i in range(10):\n",
    "\n",
    "        plt.figure(figsize=(20,10))\n",
    "        plt.subplot(1,3,1)\n",
    "        plt.imshow(X_test[i])\n",
    "        plt.title('Input')\n",
    "        plt.subplot(1,3,2)\n",
    "        plt.imshow(Y_test[i].reshape(Y_test[i].shape[0],Y_test[i].shape[1]))\n",
    "        plt.title('Ground Truth')\n",
    "        plt.subplot(1,3,3)\n",
    "        plt.imshow(yp[i].reshape(yp[i].shape[0],yp[i].shape[1]))\n",
    "        plt.title('Prediction')\n",
    "\n",
    "        intersection = yp[i].ravel() * Y_test[i].ravel()\n",
    "        union = yp[i].ravel() + Y_test[i].ravel() - intersection\n",
    "\n",
    "        jacard = (np.sum(intersection)/np.sum(union))  \n",
    "        plt.suptitle('Jacard Index'+ str(np.sum(intersection)) +'/'+ str(np.sum(union)) +'='+str(jacard))\n",
    "\n",
    "        plt.savefig('results/'+str(i)+'.png',format='png')\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "    jacard = 0\n",
    "    dice = 0\n",
    "    \n",
    "    \n",
    "    for i in range(len(Y_test)):\n",
    "        yp_2 = yp[i].ravel()\n",
    "        y2 = Y_test[i].ravel()\n",
    "        \n",
    "        intersection = yp_2 * y2\n",
    "        union = yp_2 + y2 - intersection\n",
    "\n",
    "        jacard += (np.sum(intersection)/np.sum(union))  \n",
    "\n",
    "        dice += (2. * np.sum(intersection) ) / (np.sum(yp_2) + np.sum(y2))\n",
    "\n",
    "    \n",
    "    jacard /= len(Y_test)\n",
    "    dice /= len(Y_test)\n",
    "    \n",
    "\n",
    "\n",
    "    print('Jacard Index : '+str(jacard))\n",
    "    print('Dice Coefficient : '+str(dice))\n",
    "    \n",
    "\n",
    "    fp = open('models/log.txt','a')\n",
    "    fp.write(str(jacard)+'\\n')\n",
    "    fp.close()\n",
    "\n",
    "    fp = open('models/best.txt','r')\n",
    "    best = fp.read()\n",
    "    fp.close()\n",
    "\n",
    "    if(jacard>float(best)):\n",
    "        print('***********************************************')\n",
    "        print('Jacard Index improved from '+str(best)+' to '+str(jacard))\n",
    "        print('***********************************************')\n",
    "        fp = open('models/best.txt','w')\n",
    "        fp.write(str(jacard))\n",
    "        fp.close()\n",
    "\n",
    "        saveModel(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "80IwnKtM9NHY"
   },
   "source": [
    "### Training the Model\n",
    "\n",
    "The model is trained and evaluated after each epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wlOOh0-nA05L"
   },
   "outputs": [],
   "source": [
    "def trainStep(model, X_train, Y_train, X_test, Y_test, epochs, batchSize):\n",
    "\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch : {}'.format(epoch+1))\n",
    "        model.fit(x=X_train, y=Y_train, batch_size=batchSize, epochs=1, verbose=1)     \n",
    "\n",
    "        evaluateModel(model,X_test, Y_test,batchSize)\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4wJ5V9AJ9Ygu"
   },
   "source": [
    "## Define Model, Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1105
    },
    "colab_type": "code",
    "id": "GJqeuZPhDZSK",
    "outputId": "b1344374-f69e-4805-a22d-b8152f07b754"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1\n",
      "633/633 [==============================] - 138s 219ms/step - loss: 0.3661 - dice_coef: 0.5749 - jacard: 0.4060 - accuracy: 0.9438\n",
      "71/71 [==============================] - 3s 43ms/step\n",
      "Jacard Index : 0.7857313634402245\n",
      "Dice Coefficient : 0.8764276485299455\n",
      "***********************************************\n",
      "Jacard Index improved from -1.0 to 0.7857313634402245\n",
      "***********************************************\n",
      "Epoch : 2\n",
      "633/633 [==============================] - 135s 212ms/step - loss: 0.3032 - dice_coef: 0.5915 - jacard: 0.4213 - accuracy: 0.9607\n",
      "71/71 [==============================] - 3s 49ms/step\n",
      "Jacard Index : 0.7406848524558148\n",
      "Dice Coefficient : 0.8432158209614035\n",
      "Epoch : 3\n",
      "633/633 [==============================] - 135s 214ms/step - loss: 0.2867 - dice_coef: 0.5898 - jacard: 0.4190 - accuracy: 0.9605\n",
      "71/71 [==============================] - 3s 44ms/step\n",
      "Jacard Index : 0.7826638084728127\n",
      "Dice Coefficient : 0.8622338706903647\n",
      "Epoch : 4\n",
      "633/633 [==============================] - 133s 210ms/step - loss: 0.2816 - dice_coef: 0.5872 - jacard: 0.4160 - accuracy: 0.9603\n",
      "71/71 [==============================] - 3s 45ms/step\n",
      "Jacard Index : 0.8397794921342836\n",
      "Dice Coefficient : 0.9072971613156594\n",
      "***********************************************\n",
      "Jacard Index improved from 0.7857313634402245 to 0.8397794921342836\n",
      "***********************************************\n",
      "Epoch : 5\n",
      "633/633 [==============================] - 133s 211ms/step - loss: 0.2802 - dice_coef: 0.5852 - jacard: 0.4139 - accuracy: 0.9594\n",
      "71/71 [==============================] - 4s 50ms/step\n",
      "Jacard Index : 0.8340359920027391\n",
      "Dice Coefficient : 0.9020574513505649\n",
      "Epoch : 6\n",
      "633/633 [==============================] - 135s 213ms/step - loss: 0.2799 - dice_coef: 0.5849 - jacard: 0.4136 - accuracy: 0.9593\n",
      "71/71 [==============================] - 3s 45ms/step\n",
      "Jacard Index : 0.8391951167217424\n",
      "Dice Coefficient : 0.9080397891357069\n",
      "Epoch : 7\n",
      "633/633 [==============================] - 138s 218ms/step - loss: 0.2792 - dice_coef: 0.5851 - jacard: 0.4138 - accuracy: 0.9597\n",
      "71/71 [==============================] - 3s 46ms/step\n",
      "Jacard Index : 0.8264127536400537\n",
      "Dice Coefficient : 0.8956840340492954\n",
      "Epoch : 8\n",
      "633/633 [==============================] - 133s 210ms/step - loss: 0.2782 - dice_coef: 0.5858 - jacard: 0.4145 - accuracy: 0.9610\n",
      "71/71 [==============================] - 3s 44ms/step\n",
      "Jacard Index : 0.8135437299125711\n",
      "Dice Coefficient : 0.8905632247632275\n",
      "Epoch : 9\n",
      "633/633 [==============================] - 138s 218ms/step - loss: 0.2776 - dice_coef: 0.5864 - jacard: 0.4151 - accuracy: 0.9617\n",
      "71/71 [==============================] - 4s 50ms/step\n",
      "Jacard Index : 0.8456862347858879\n",
      "Dice Coefficient : 0.9115826597064148\n",
      "***********************************************\n",
      "Jacard Index improved from 0.8397794921342836 to 0.8456862347858879\n",
      "***********************************************\n",
      "Epoch : 10\n",
      "633/633 [==============================] - 131s 207ms/step - loss: 0.2780 - dice_coef: 0.5858 - jacard: 0.4146 - accuracy: 0.9613\n",
      "71/71 [==============================] - 3s 43ms/step\n",
      "Jacard Index : 0.7817826096249479\n",
      "Dice Coefficient : 0.8687784828404101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.training.Model at 0x7fe5f01aaee0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultiResUnet(height=64, width=64, n_channels=1)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef, jacard, 'accuracy'])\n",
    "\n",
    "saveModel(model)\n",
    "\n",
    "fp = open('models/log.txt','w')\n",
    "fp.close()\n",
    "fp = open('models/best.txt','w')\n",
    "fp.write('-1.0')\n",
    "fp.close()\n",
    "    \n",
    "trainStep(model, X_train, Y_train, X_test, Y_test, epochs=10, batchSize=1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ISIC.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
