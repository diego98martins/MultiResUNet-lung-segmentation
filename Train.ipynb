{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SKD7jSvIn1T9"
   },
   "source": [
    "# Importing Modules\n",
    "\n",
    "The necessary modules are : os, opencv, numpy, tqdm, matplotlib, imgaug, tensorflow and sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nNtz_YYVnzcZ",
    "outputId": "21000b0d-93c5-4dcf-96f3-4bedc5d90a3c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables.segmaps import SegmentationMapsOnImage\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, BatchNormalization, Activation, add\n",
    "from tensorflow.keras.models import Model, model_from_json\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import ELU, LeakyReLU\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import backend as K \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xLkeS7Lxo_Po"
   },
   "source": [
    "# Constructing Training and Test Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gHo6ymwFpJzY"
   },
   "source": [
    "## Loading the Images\n",
    "\n",
    "We first load all the images and the corresponding segmentation masks. \n",
    "\n",
    "They are stored in two lists X, Y and respectively\n",
    "\n",
    "Moreover, the images are resized to 64x64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "YbeQ1aytHTm3",
    "outputId": "d43c1e52-d889-4a4f-96aa-5ef4d20b649f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 20/704 [00:00<00:03, 196.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704\n",
      "704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 704/704 [00:03<00:00, 225.05it/s]\n"
     ]
    }
   ],
   "source": [
    "img_files = next(os.walk('data/cxr'))[2]\n",
    "msk_files = next(os.walk('data/masks'))[2]\n",
    "\n",
    "img_files.sort()\n",
    "msk_files.sort()\n",
    "\n",
    "print(len(img_files))\n",
    "print(len(msk_files))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for img_fl in tqdm(img_files):    \n",
    "    if(img_fl.split('.')[-1]=='png'):\n",
    "                \n",
    "        \n",
    "        img = cv2.imread('data/cxr/{}'.format(img_fl), cv2.IMREAD_GRAYSCALE)\n",
    "        resized_img = cv2.resize(img,(64, 64), interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "        X.append(resized_img)\n",
    "\n",
    "        msk = cv2.imread('data/masks/{}'.format(img_fl), cv2.IMREAD_GRAYSCALE)\n",
    "        resized_msk = cv2.resize(msk,(64, 64), interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "        Y.append(resized_msk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation\n",
    "\n",
    "We generate more data for training using the original dataset.\n",
    "\n",
    "Operations:\n",
    "\n",
    "* dropout pixels\n",
    "* change scale\n",
    "* rotate\n",
    "* horizontal flip\n",
    "* crop\n",
    "* contrast\n",
    "* and others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "masks = []\n",
    "\n",
    "for i in range(len(X)):\n",
    "    # Load an example image (uint8, 64x64).\n",
    "    image = np.array(X[i], dtype=np.uint8)\n",
    "\n",
    "    # Define an example segmentation map (int32, 64x64).\n",
    "    segmap = np.array(Y[i])\n",
    "    segmap = segmap / 255\n",
    "    segmap = np.around(segmap, decimals=0)\n",
    "    segmap = np.array(segmap, dtype=np.int32)\n",
    "\n",
    "    segmap = SegmentationMapsOnImage(segmap, shape=image.shape)\n",
    "\n",
    "    # Define our augmentation pipeline.\n",
    "    seq = iaa.Sequential([\n",
    "        iaa.Dropout([0.0, 0.004]),      # drop 0% to 0.4% of all pixels\n",
    "        iaa.Sharpen((0.0, 1.0)),       # sharpen the image\n",
    "        iaa.Affine(\n",
    "            scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)},\n",
    "            translate_percent={\"x\": (-0.05, 0.05), \"y\": (-0.05, 0.05)},\n",
    "            rotate=(-10, 10),\n",
    "            shear=(-8, 8)\n",
    "        ),\n",
    "        iaa.ElasticTransformation(alpha=0.1, sigma=0.03),\n",
    "        iaa.Fliplr(0.5),\n",
    "        iaa.LinearContrast((0.75, 1.5)),\n",
    "        iaa.Crop(percent=(0, 0.05)),\n",
    "\n",
    "        iaa.Sometimes(\n",
    "            0.5,\n",
    "            iaa.GaussianBlur(sigma=(0, 0.5))\n",
    "        ),\n",
    "    ], random_order=True)\n",
    "\n",
    "    # Augment images and segmaps.\n",
    "    images_aug = []\n",
    "    segmaps_aug = []\n",
    "    for _ in range(15): #e.g. range(15) = 15 new image are generate per 1 original image\n",
    "        images_aug_i, segmaps_aug_i = seq(image=image, segmentation_maps=segmap)\n",
    "        images_aug.append(images_aug_i)\n",
    "        segmaps_aug.append(segmaps_aug_i)\n",
    "\n",
    "\n",
    "    for image_aug, segmap_aug in zip(images_aug, segmaps_aug):\n",
    "        imgs.append(image_aug)  \n",
    "        \n",
    "        mask = cv2.cvtColor(segmap_aug.draw(size=image_aug.shape[:2])[0], cv2.COLOR_BGR2GRAY)\n",
    "        mask = cv2.medianBlur(mask, 5)\n",
    "        masks.append(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jYgEz9HQpgsR"
   },
   "source": [
    "## Train-Test Split\n",
    "\n",
    "The X, Y lists are converted to numpy arrays for convenience. \n",
    "Furthermore, the images are divided by 255 to bring down the pixel values to [0...1] range. On the other hand the segmentations masks are converted to binary (0 or 1) values.\n",
    "\n",
    "Using Sklearn *train_test_split* we split the data randomly into 80% training and 20% testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "CxFIZv3715Dt",
    "outputId": "5a93db60-ed50-4122-8aa0-b26e42a601ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10560\n",
      "10560\n",
      "(9504, 64, 64)\n",
      "(9504, 64, 64, 1)\n",
      "(1056, 64, 64)\n",
      "(1056, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "print(len(imgs))\n",
    "print(len(masks))\n",
    "\n",
    "X = np.array(imgs)\n",
    "Y = np.array(masks)\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=3)\n",
    "\n",
    "Y_train = Y_train.reshape((Y_train.shape[0],Y_train.shape[1],Y_train.shape[2],1))\n",
    "Y_test = Y_test.reshape((Y_test.shape[0],Y_test.shape[1],Y_test.shape[2],1))\n",
    "\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "Y_train = np.where(Y_train == 0, 0, 1)\n",
    "Y_test = np.where(Y_test == 0, 0, 1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C-Ajp2QVrMti"
   },
   "source": [
    "# MultiResUNet Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "21cbmiojrYrU"
   },
   "source": [
    "## Model Definition\n",
    "\n",
    "The MultiResUNet model as described in the [paper](https://arxiv.org/abs/1902.04049) can be found  [here](https://github.com/nibtehaz/MultiResUNet/blob/master/MultiResUNet.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2nX7I1Wf_zEy"
   },
   "outputs": [],
   "source": [
    "def conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(1, 1), activation='relu', name=None):\n",
    "    '''\n",
    "    2D Convolutional layers\n",
    "    \n",
    "    Arguments:\n",
    "        x {keras layer} -- input layer \n",
    "        filters {int} -- number of filters\n",
    "        num_row {int} -- number of rows in filters\n",
    "        num_col {int} -- number of columns in filters\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        padding {str} -- mode of padding (default: {'same'})\n",
    "        strides {tuple} -- stride of convolution operation (default: {(1, 1)})\n",
    "        activation {str} -- activation function (default: {'relu'})\n",
    "        name {str} -- name of the layer (default: {None})\n",
    "    \n",
    "    Returns:\n",
    "        [keras layer] -- [output layer]\n",
    "    '''\n",
    "\n",
    "    x = Conv2D(filters, (num_row, num_col), strides=strides, padding=padding, use_bias=False)(x)\n",
    "    x = BatchNormalization(axis=3, scale=False)(x)\n",
    "\n",
    "    if(activation == None):\n",
    "        return x\n",
    "\n",
    "    x = Activation(activation, name=name)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def trans_conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(2, 2), name=None):\n",
    "    '''\n",
    "    2D Transposed Convolutional layers\n",
    "    \n",
    "    Arguments:\n",
    "        x {keras layer} -- input layer \n",
    "        filters {int} -- number of filters\n",
    "        num_row {int} -- number of rows in filters\n",
    "        num_col {int} -- number of columns in filters\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        padding {str} -- mode of padding (default: {'same'})\n",
    "        strides {tuple} -- stride of convolution operation (default: {(2, 2)})\n",
    "        name {str} -- name of the layer (default: {None})\n",
    "    \n",
    "    Returns:\n",
    "        [keras layer] -- [output layer]\n",
    "    '''\n",
    "\n",
    "    x = Conv2DTranspose(filters, (num_row, num_col), strides=strides, padding=padding)(x)\n",
    "    x = BatchNormalization(axis=3, scale=False)(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def MultiResBlock(U, inp, alpha = 1.67):\n",
    "    '''\n",
    "    MultiRes Block\n",
    "    \n",
    "    Arguments:\n",
    "        U {int} -- Number of filters in a corrsponding UNet stage\n",
    "        inp {keras layer} -- input layer \n",
    "    \n",
    "    Returns:\n",
    "        [keras layer] -- [output layer]\n",
    "    '''\n",
    "\n",
    "    W = alpha * U\n",
    "\n",
    "    shortcut = inp\n",
    "\n",
    "    shortcut = conv2d_bn(shortcut, int(W*0.167) + int(W*0.333) +\n",
    "                         int(W*0.5), 1, 1, activation=None, padding='same')\n",
    "\n",
    "    conv3x3 = conv2d_bn(inp, int(W*0.167), 3, 3,\n",
    "                        activation='relu', padding='same')\n",
    "\n",
    "    conv5x5 = conv2d_bn(conv3x3, int(W*0.333), 3, 3,\n",
    "                        activation='relu', padding='same')\n",
    "\n",
    "    conv7x7 = conv2d_bn(conv5x5, int(W*0.5), 3, 3,\n",
    "                        activation='relu', padding='same')\n",
    "\n",
    "    out = concatenate([conv3x3, conv5x5, conv7x7], axis=3)\n",
    "    out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    out = add([shortcut, out])\n",
    "    out = Activation('relu')(out)\n",
    "    out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def ResPath(filters, length, inp):\n",
    "    '''\n",
    "    ResPath\n",
    "    \n",
    "    Arguments:\n",
    "        filters {int} -- [description]\n",
    "        length {int} -- length of ResPath\n",
    "        inp {keras layer} -- input layer \n",
    "    \n",
    "    Returns:\n",
    "        [keras layer] -- [output layer]\n",
    "    '''\n",
    "\n",
    "\n",
    "    shortcut = inp\n",
    "    shortcut = conv2d_bn(shortcut, filters, 1, 1,\n",
    "                         activation=None, padding='same')\n",
    "\n",
    "    out = conv2d_bn(inp, filters, 3, 3, activation='relu', padding='same')\n",
    "\n",
    "    out = add([shortcut, out])\n",
    "    out = Activation('relu')(out)\n",
    "    out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    for i in range(length-1):\n",
    "\n",
    "        shortcut = out\n",
    "        shortcut = conv2d_bn(shortcut, filters, 1, 1,\n",
    "                             activation=None, padding='same')\n",
    "\n",
    "        out = conv2d_bn(out, filters, 3, 3, activation='relu', padding='same')\n",
    "\n",
    "        out = add([shortcut, out])\n",
    "        out = Activation('relu')(out)\n",
    "        out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def MultiResUnet(height, width, n_channels):\n",
    "    '''\n",
    "    MultiResUNet\n",
    "    \n",
    "    Arguments:\n",
    "        height {int} -- height of image \n",
    "        width {int} -- width of image \n",
    "        n_channels {int} -- number of channels in image\n",
    "    \n",
    "    Returns:\n",
    "        [keras model] -- MultiResUNet model\n",
    "    '''\n",
    "\n",
    "\n",
    "    inputs = Input((height, width, n_channels))\n",
    "\n",
    "    mresblock1 = MultiResBlock(32, inputs)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(mresblock1)\n",
    "    mresblock1 = ResPath(32, 4, mresblock1)\n",
    "\n",
    "    mresblock2 = MultiResBlock(32*2, pool1)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(mresblock2)\n",
    "    mresblock2 = ResPath(32*2, 3, mresblock2)\n",
    "\n",
    "    mresblock3 = MultiResBlock(32*4, pool2)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(mresblock3)\n",
    "    mresblock3 = ResPath(32*4, 2, mresblock3)\n",
    "\n",
    "    mresblock4 = MultiResBlock(32*8, pool3)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(mresblock4)\n",
    "    mresblock4 = ResPath(32*8, 1, mresblock4)\n",
    "\n",
    "    mresblock5 = MultiResBlock(32*16, pool4)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(\n",
    "        32*8, (2, 2), strides=(2, 2), padding='same')(mresblock5), mresblock4], axis=3)\n",
    "    mresblock6 = MultiResBlock(32*8, up6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(\n",
    "        32*4, (2, 2), strides=(2, 2), padding='same')(mresblock6), mresblock3], axis=3)\n",
    "    mresblock7 = MultiResBlock(32*4, up7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(\n",
    "        32*2, (2, 2), strides=(2, 2), padding='same')(mresblock7), mresblock2], axis=3)\n",
    "    mresblock8 = MultiResBlock(32*2, up8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(\n",
    "        2, 2), padding='same')(mresblock8), mresblock1], axis=3)\n",
    "    mresblock9 = MultiResBlock(32, up9)\n",
    "\n",
    "    conv10 = conv2d_bn(mresblock9, 1, 1, 1, activation='sigmoid')\n",
    "    \n",
    "    model = Model(inputs=[inputs], outputs=[conv10])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2frZlpmFsv1f"
   },
   "source": [
    "## Auxiliary Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "degBGBWYsyNG"
   },
   "source": [
    "### Custom Metrics\n",
    "\n",
    "Since Keras does not have build-in support for computing Dice Coefficient or Jaccard Index (at the time of writing), the following functions are declared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xq8qfLqDA6q2"
   },
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    smooth = 0.0\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def jacard(y_true, y_pred):\n",
    "\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum ( y_true_f * y_pred_f)\n",
    "    union = K.sum ( y_true_f + y_pred_f - y_true_f * y_pred_f)\n",
    "\n",
    "    return intersection/union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VtvyeBXy8Mk3"
   },
   "source": [
    "### Saving Model \n",
    "\n",
    "Function to save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GCfX9MUYALar"
   },
   "outputs": [],
   "source": [
    "def saveModel(model):\n",
    "\n",
    "    model_json = model.to_json()\n",
    "\n",
    "    try:\n",
    "        os.makedirs('models')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    fp = open('models/modelP.json','w')\n",
    "    fp.write(model_json)\n",
    "    model.save_weights('models/modelW.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AH3znjx-8vDq"
   },
   "source": [
    "### Evaluate the Model\n",
    "\n",
    "We evaluate the model on test data (X_test, Y_test). \n",
    "\n",
    "We compute the values of Jaccard Index and Dice Coeficient, and save the predicted segmentation of first 10 images. The best model is also saved\n",
    "\n",
    "(This could have been done using keras call-backs as well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tkit_YYvBQ7V"
   },
   "outputs": [],
   "source": [
    "def evaluateModel(model, X_test, Y_test, batchSize):\n",
    "    \n",
    "    try:\n",
    "        os.makedirs('results')\n",
    "    except:\n",
    "        pass \n",
    "    \n",
    "\n",
    "    yp = model.predict(x=X_test, batch_size=batchSize, verbose=1)\n",
    "\n",
    "    yp = np.round(yp,0)\n",
    "\n",
    "    for i in range(10):\n",
    "\n",
    "        plt.figure(figsize=(20,10))\n",
    "        plt.subplot(1,3,1)\n",
    "        plt.imshow(X_test[i])\n",
    "        plt.title('Input')\n",
    "        plt.subplot(1,3,2)\n",
    "        plt.imshow(Y_test[i].reshape(Y_test[i].shape[0],Y_test[i].shape[1]))\n",
    "        plt.title('Ground Truth')\n",
    "        plt.subplot(1,3,3)\n",
    "        plt.imshow(yp[i].reshape(yp[i].shape[0],yp[i].shape[1]))\n",
    "        plt.title('Prediction')\n",
    "\n",
    "        intersection = yp[i].ravel() * Y_test[i].ravel()\n",
    "        union = yp[i].ravel() + Y_test[i].ravel() - intersection\n",
    "\n",
    "        jacard = (np.sum(intersection)/np.sum(union))  \n",
    "        plt.suptitle('Jacard Index'+ str(np.sum(intersection)) +'/'+ str(np.sum(union)) +'='+str(jacard))\n",
    "\n",
    "        plt.savefig('results/'+str(i)+'.png',format='png')\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "    jacard = 0\n",
    "    dice = 0\n",
    "    \n",
    "    \n",
    "    for i in range(len(Y_test)):\n",
    "        yp_2 = yp[i].ravel()\n",
    "        y2 = Y_test[i].ravel()\n",
    "        \n",
    "        intersection = yp_2 * y2\n",
    "        union = yp_2 + y2 - intersection\n",
    "\n",
    "        jacard += (np.sum(intersection)/np.sum(union))  \n",
    "\n",
    "        dice += (2. * np.sum(intersection) ) / (np.sum(yp_2) + np.sum(y2))\n",
    "\n",
    "    \n",
    "    jacard /= len(Y_test)\n",
    "    dice /= len(Y_test)\n",
    "    \n",
    "\n",
    "\n",
    "    print('Jacard Index : '+str(jacard))\n",
    "    print('Dice Coefficient : '+str(dice))\n",
    "    \n",
    "\n",
    "    fp = open('models/log.txt','a')\n",
    "    fp.write(str(jacard)+'\\n')\n",
    "    fp.close()\n",
    "\n",
    "    fp = open('models/best.txt','r')\n",
    "    best = fp.read()\n",
    "    fp.close()\n",
    "\n",
    "    if(jacard>float(best)):\n",
    "        print('***********************************************')\n",
    "        print('Jacard Index improved from '+str(best)+' to '+str(jacard))\n",
    "        print('***********************************************')\n",
    "        fp = open('models/best.txt','w')\n",
    "        fp.write(str(jacard))\n",
    "        fp.close()\n",
    "\n",
    "        saveModel(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "80IwnKtM9NHY"
   },
   "source": [
    "### Training the Model\n",
    "\n",
    "The model is trained and evaluated after each epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wlOOh0-nA05L"
   },
   "outputs": [],
   "source": [
    "def trainStep(model, X_train, Y_train, X_test, Y_test, epochs, batchSize):\n",
    "\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch : {}'.format(epoch+1))\n",
    "        model.fit(x=X_train, y=Y_train, batch_size=batchSize, epochs=1, verbose=1)     \n",
    "\n",
    "        evaluateModel(model,X_test, Y_test,batchSize)\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4wJ5V9AJ9Ygu"
   },
   "source": [
    "## Define Model, Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1105
    },
    "colab_type": "code",
    "id": "GJqeuZPhDZSK",
    "outputId": "b1344374-f69e-4805-a22d-b8152f07b754"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1\n",
      "297/297 [==============================] - 1553s 5s/step - loss: 0.3737 - dice_coef: 0.5854 - jacard: 0.4143 - accuracy: 0.9527\n",
      "33/33 [==============================] - 33s 998ms/step\n",
      "Jacard Index : 0.8329909238890746\n",
      "Dice Coefficient : 0.9070344814381542\n",
      "***********************************************\n",
      "Jacard Index improved from -1.0 to 0.8329909238890746\n",
      "***********************************************\n",
      "Epoch : 2\n",
      "297/297 [==============================] - 1559s 5s/step - loss: 0.3212 - dice_coef: 0.6033 - jacard: 0.4320 - accuracy: 0.9697\n",
      "33/33 [==============================] - 33s 999ms/step\n",
      "Jacard Index : 0.8963179718631933\n",
      "Dice Coefficient : 0.9447059413499677\n",
      "***********************************************\n",
      "Jacard Index improved from 0.8329909238890746 to 0.8963179718631933\n",
      "***********************************************\n",
      "Epoch : 3\n",
      "297/297 [==============================] - 1544s 5s/step - loss: 0.2955 - dice_coef: 0.6085 - jacard: 0.4373 - accuracy: 0.9713\n",
      "33/33 [==============================] - 33s 999ms/step\n",
      "Jacard Index : 0.889008851057422\n",
      "Dice Coefficient : 0.9404906759390065\n",
      "Epoch : 4\n",
      "297/297 [==============================] - 1545s 5s/step - loss: 0.2816 - dice_coef: 0.6084 - jacard: 0.4373 - accuracy: 0.9711\n",
      "33/33 [==============================] - 33s 1s/step\n",
      "Jacard Index : 0.8910842859852114\n",
      "Dice Coefficient : 0.9417806001639941\n",
      "Epoch : 5\n",
      "297/297 [==============================] - 1553s 5s/step - loss: 0.2736 - dice_coef: 0.6065 - jacard: 0.4353 - accuracy: 0.9712\n",
      "33/33 [==============================] - 33s 1s/step\n",
      "Jacard Index : 0.8924626785095675\n",
      "Dice Coefficient : 0.9426884721375448\n",
      "Epoch : 6\n",
      "297/297 [==============================] - 1546s 5s/step - loss: 0.2698 - dice_coef: 0.6036 - jacard: 0.4323 - accuracy: 0.9709\n",
      "33/33 [==============================] - 33s 1s/step\n",
      "Jacard Index : 0.8853894064644685\n",
      "Dice Coefficient : 0.9386078192923533\n",
      "Epoch : 7\n",
      "297/297 [==============================] - 1546s 5s/step - loss: 0.2680 - dice_coef: 0.6010 - jacard: 0.4296 - accuracy: 0.9706\n",
      "33/33 [==============================] - 33s 1s/step\n",
      "Jacard Index : 0.8842864955737262\n",
      "Dice Coefficient : 0.9378789229337583\n",
      "Epoch : 8\n",
      "297/297 [==============================] - 1549s 5s/step - loss: 0.2667 - dice_coef: 0.5996 - jacard: 0.4281 - accuracy: 0.9710\n",
      "33/33 [==============================] - 33s 1s/step\n",
      "Jacard Index : 0.888758905443582\n",
      "Dice Coefficient : 0.9404532856743275\n",
      "Epoch : 9\n",
      "297/297 [==============================] - 1549s 5s/step - loss: 0.2660 - dice_coef: 0.5986 - jacard: 0.4272 - accuracy: 0.9714\n",
      "33/33 [==============================] - 33s 1s/step\n",
      "Jacard Index : 0.8880345453270186\n",
      "Dice Coefficient : 0.9401680709166864\n",
      "Epoch : 10\n",
      "297/297 [==============================] - 1548s 5s/step - loss: 0.2651 - dice_coef: 0.5987 - jacard: 0.4273 - accuracy: 0.9724\n",
      "33/33 [==============================] - 33s 1s/step\n",
      "Jacard Index : 0.8951341267001409\n",
      "Dice Coefficient : 0.9441518264582124\n",
      "Epoch : 11\n",
      "297/297 [==============================] - 1548s 5s/step - loss: 0.2645 - dice_coef: 0.5989 - jacard: 0.4274 - accuracy: 0.9732\n",
      "33/33 [==============================] - 33s 1s/step\n",
      "Jacard Index : 0.8949768218125692\n",
      "Dice Coefficient : 0.9440518676207492\n",
      "Epoch : 12\n",
      "297/297 [==============================] - 1548s 5s/step - loss: 0.2637 - dice_coef: 0.5997 - jacard: 0.4282 - accuracy: 0.9744\n",
      "33/33 [==============================] - 33s 1s/step\n",
      "Jacard Index : 0.8912029926764695\n",
      "Dice Coefficient : 0.9419612502865053\n",
      "Epoch : 13\n",
      "297/297 [==============================] - 1549s 5s/step - loss: 0.2635 - dice_coef: 0.5994 - jacard: 0.4280 - accuracy: 0.9745\n",
      "33/33 [==============================] - 33s 1s/step\n",
      "Jacard Index : 0.8876058221689078\n",
      "Dice Coefficient : 0.9397725629723808\n",
      "Epoch : 14\n",
      "297/297 [==============================] - 1550s 5s/step - loss: 0.2627 - dice_coef: 0.6003 - jacard: 0.4289 - accuracy: 0.9756\n",
      "33/33 [==============================] - 33s 1s/step\n",
      "Jacard Index : 0.892630547213124\n",
      "Dice Coefficient : 0.9427291445724357\n",
      "Epoch : 15\n",
      "297/297 [==============================] - 1551s 5s/step - loss: 0.2618 - dice_coef: 0.6011 - jacard: 0.4297 - accuracy: 0.9770\n",
      "33/33 [==============================] - 33s 1s/step\n",
      "Jacard Index : 0.8954277438481552\n",
      "Dice Coefficient : 0.9443442657673199\n",
      "Epoch : 16\n",
      "297/297 [==============================] - 1551s 5s/step - loss: 0.2613 - dice_coef: 0.6015 - jacard: 0.4301 - accuracy: 0.9777\n",
      "33/33 [==============================] - 33s 1s/step\n",
      "Jacard Index : 0.893678724720214\n",
      "Dice Coefficient : 0.9433116009202518\n",
      "Epoch : 17\n",
      "297/297 [==============================] - 1551s 5s/step - loss: 0.2620 - dice_coef: 0.6011 - jacard: 0.4297 - accuracy: 0.9768\n",
      "33/33 [==============================] - 33s 1s/step\n",
      "Jacard Index : 0.897391813789935\n",
      "Dice Coefficient : 0.9453656821702648\n",
      "***********************************************\n",
      "Jacard Index improved from 0.8963179718631933 to 0.897391813789935\n",
      "***********************************************\n",
      "Epoch : 18\n",
      "297/297 [==============================] - 1551s 5s/step - loss: 0.2606 - dice_coef: 0.6020 - jacard: 0.4306 - accuracy: 0.9786\n",
      "33/33 [==============================] - 33s 1s/step\n",
      "Jacard Index : 0.8954438878325668\n",
      "Dice Coefficient : 0.9443347384351021\n",
      "Epoch : 19\n",
      "297/297 [==============================] - 1551s 5s/step - loss: 0.2598 - dice_coef: 0.6028 - jacard: 0.4315 - accuracy: 0.9799\n",
      "33/33 [==============================] - 33s 1s/step\n",
      "Jacard Index : 0.8914274730920696\n",
      "Dice Coefficient : 0.942067891319665\n",
      "Epoch : 20\n",
      "297/297 [==============================] - 1551s 5s/step - loss: 0.2594 - dice_coef: 0.6032 - jacard: 0.4319 - accuracy: 0.9804\n",
      "33/33 [==============================] - 33s 1s/step\n",
      "Jacard Index : 0.8974393245198269\n",
      "Dice Coefficient : 0.9454641100374838\n",
      "***********************************************\n",
      "Jacard Index improved from 0.897391813789935 to 0.8974393245198269\n",
      "***********************************************\n",
      "Epoch : 21\n",
      "297/297 [==============================] - 1551s 5s/step - loss: 0.2591 - dice_coef: 0.6035 - jacard: 0.4321 - accuracy: 0.9810\n",
      "33/33 [==============================] - 33s 1s/step\n",
      "Jacard Index : 0.8995721095557846\n",
      "Dice Coefficient : 0.9466787438071529\n",
      "***********************************************\n",
      "Jacard Index improved from 0.8974393245198269 to 0.8995721095557846\n",
      "***********************************************\n",
      "Epoch : 22\n",
      "297/297 [==============================] - 1552s 5s/step - loss: 0.2583 - dice_coef: 0.6040 - jacard: 0.4326 - accuracy: 0.9820\n",
      "33/33 [==============================] - 33s 1s/step\n",
      "Jacard Index : 0.9000042225183542\n",
      "Dice Coefficient : 0.9468457713354557\n",
      "***********************************************\n",
      "Jacard Index improved from 0.8995721095557846 to 0.9000042225183542\n",
      "***********************************************\n",
      "Epoch : 23\n",
      "297/297 [==============================] - 1550s 5s/step - loss: 0.2576 - dice_coef: 0.6046 - jacard: 0.4333 - accuracy: 0.9829\n",
      "33/33 [==============================] - 33s 1s/step\n",
      "Jacard Index : 0.8920691353126793\n",
      "Dice Coefficient : 0.9424346046067082\n",
      "Epoch : 24\n",
      "297/297 [==============================] - 1551s 5s/step - loss: 0.2573 - dice_coef: 0.6049 - jacard: 0.4336 - accuracy: 0.9834\n",
      "33/33 [==============================] - 33s 1s/step\n",
      "Jacard Index : 0.905693556762083\n",
      "Dice Coefficient : 0.9499866559816444\n",
      "***********************************************\n",
      "Jacard Index improved from 0.9000042225183542 to 0.905693556762083\n",
      "***********************************************\n",
      "Epoch : 25\n",
      "297/297 [==============================] - 1552s 5s/step - loss: 0.2573 - dice_coef: 0.6050 - jacard: 0.4337 - accuracy: 0.9835\n",
      "33/33 [==============================] - 33s 1s/step\n",
      "Jacard Index : 0.8970890876019348\n",
      "Dice Coefficient : 0.9452584561613517\n",
      "Epoch : 26\n",
      "297/297 [==============================] - 1551s 5s/step - loss: 0.2572 - dice_coef: 0.6050 - jacard: 0.4337 - accuracy: 0.9837\n",
      "33/33 [==============================] - 33s 1s/step\n",
      "Jacard Index : 0.900387826614493\n",
      "Dice Coefficient : 0.9471068502121458\n",
      "Epoch : 27\n",
      "297/297 [==============================] - 1551s 5s/step - loss: 0.2568 - dice_coef: 0.6055 - jacard: 0.4342 - accuracy: 0.9843\n",
      "33/33 [==============================] - 33s 1s/step\n",
      "Jacard Index : 0.9054733739831139\n",
      "Dice Coefficient : 0.9499246947899843\n",
      "Epoch : 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297/297 [==============================] - 1555s 5s/step - loss: 0.2559 - dice_coef: 0.6061 - jacard: 0.4348 - accuracy: 0.9855\n",
      "33/33 [==============================] - 33s 999ms/step\n",
      "Jacard Index : 0.9056813002859784\n",
      "Dice Coefficient : 0.9500349135469993\n",
      "Epoch : 29\n",
      "297/297 [==============================] - 1549s 5s/step - loss: 0.2551 - dice_coef: 0.6069 - jacard: 0.4356 - accuracy: 0.9867\n",
      "33/33 [==============================] - 33s 1s/step\n",
      "Jacard Index : 0.9024255037988342\n",
      "Dice Coefficient : 0.9482408197558446\n",
      "Epoch : 30\n",
      "297/297 [==============================] - 1554s 5s/step - loss: 0.2546 - dice_coef: 0.6072 - jacard: 0.4359 - accuracy: 0.9874\n",
      "33/33 [==============================] - 33s 1s/step\n",
      "Jacard Index : 0.9070465447137017\n",
      "Dice Coefficient : 0.9507885419684656\n",
      "***********************************************\n",
      "Jacard Index improved from 0.905693556762083 to 0.9070465447137017\n",
      "***********************************************\n",
      "Epoch : 31\n",
      "297/297 [==============================] - 1548s 5s/step - loss: 0.2544 - dice_coef: 0.6076 - jacard: 0.4364 - accuracy: 0.9878\n",
      "33/33 [==============================] - 33s 1s/step\n",
      "Jacard Index : 0.899422432496444\n",
      "Dice Coefficient : 0.946569334329391\n",
      "Epoch : 32\n",
      "297/297 [==============================] - 1551s 5s/step - loss: 0.2544 - dice_coef: 0.6073 - jacard: 0.4361 - accuracy: 0.9878\n",
      "33/33 [==============================] - 33s 1s/step\n",
      "Jacard Index : 0.9020670581410465\n",
      "Dice Coefficient : 0.9479949593082853\n",
      "Epoch : 33\n",
      "297/297 [==============================] - 1551s 5s/step - loss: 0.2543 - dice_coef: 0.6076 - jacard: 0.4364 - accuracy: 0.9880\n",
      "33/33 [==============================] - 33s 1s/step\n",
      "Jacard Index : 0.9012745440520709\n",
      "Dice Coefficient : 0.9475444766147242\n",
      "Epoch : 34\n",
      "297/297 [==============================] - 1577s 5s/step - loss: 0.2543 - dice_coef: 0.6077 - jacard: 0.4365 - accuracy: 0.9880\n",
      "33/33 [==============================] - 40s 1s/step\n",
      "Jacard Index : 0.9032361692253577\n",
      "Dice Coefficient : 0.948661511834775\n",
      "Epoch : 35\n",
      "297/297 [==============================] - 1554s 5s/step - loss: 0.2531 - dice_coef: 0.6085 - jacard: 0.4373 - accuracy: 0.9896\n",
      "33/33 [==============================] - 33s 1s/step\n",
      "Jacard Index : 0.9069224961844609\n",
      "Dice Coefficient : 0.9507192728080524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.training.Model at 0x7f3c8eecd9d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultiResUnet(height=64, width=64, n_channels=1)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef, jacard, 'accuracy'])\n",
    "\n",
    "saveModel(model)\n",
    "\n",
    "fp = open('models/log.txt','w')\n",
    "fp.close()\n",
    "fp = open('models/best.txt','w')\n",
    "fp.write('-1.0')\n",
    "fp.close()\n",
    "    \n",
    "trainStep(model, X_train, Y_train, X_test, Y_test, epochs=35, batchSize=32)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ISIC.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
